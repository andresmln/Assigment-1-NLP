{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e1ff66b-76d5-4d66-988e-31213289f62e",
   "metadata": {},
   "source": [
    "**First we load and merge train, val and test datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95206848-e7d9-4cd7-a856-0817772dbfff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Examples: 8865\n",
      "  Argument ID                                   Conclusion       Stance  \\\n",
      "0      A01002                  We should ban human cloning  in favor of   \n",
      "1      A01005                      We should ban fast food  in favor of   \n",
      "2      A01006  We should end the use of economic sanctions      against   \n",
      "\n",
      "                                             Premise  Self-direction: thought  \\\n",
      "0  we should ban human cloning as it will only ca...                        0   \n",
      "1  fast food should be banned because it is reall...                        0   \n",
      "2  sometimes economic sanctions are the only thin...                        0   \n",
      "\n",
      "   Self-direction: action  Stimulation  Hedonism  Achievement  \\\n",
      "0                       0            0         0            0   \n",
      "1                       0            0         0            0   \n",
      "2                       0            0         0            0   \n",
      "\n",
      "   Power: dominance  ...  Tradition  Conformity: rules  \\\n",
      "0                 0  ...          0                  0   \n",
      "1                 0  ...          0                  0   \n",
      "2                 1  ...          0                  0   \n",
      "\n",
      "   Conformity: interpersonal  Humility  Benevolence: caring  \\\n",
      "0                          0         0                    0   \n",
      "1                          0         0                    0   \n",
      "2                          0         0                    0   \n",
      "\n",
      "   Benevolence: dependability  Universalism: concern  Universalism: nature  \\\n",
      "0                           0                      0                     0   \n",
      "1                           0                      0                     0   \n",
      "2                           0                      0                     0   \n",
      "\n",
      "   Universalism: tolerance  Universalism: objectivity  \n",
      "0                        0                          0  \n",
      "1                        0                          0  \n",
      "2                        0                          0  \n",
      "\n",
      "[3 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Load Training Data\n",
    "train_args = pd.read_csv(\"data/arguments-training.tsv\", sep='\\t')\n",
    "train_labels = pd.read_csv(\"data/labels-training.tsv\", sep='\\t')\n",
    "df_train = pd.merge(train_args, train_labels, on=\"Argument ID\")\n",
    "\n",
    "# 2. Load Validation Data\n",
    "val_args = pd.read_csv(\"data/arguments-validation.tsv\", sep='\\t')\n",
    "val_labels = pd.read_csv(\"data/labels-validation.tsv\", sep='\\t')\n",
    "df_val = pd.merge(val_args, val_labels, on=\"Argument ID\")\n",
    "\n",
    "# 3. Load Test Data (Crucial for volume!)\n",
    "test_args = pd.read_csv(\"data/arguments-test.tsv\", sep='\\t')\n",
    "test_labels = pd.read_csv(\"data/labels-test.tsv\", sep='\\t')\n",
    "df_test = pd.merge(test_args, test_labels, on=\"Argument ID\")\n",
    "\n",
    "# 4. Concatenate EVERYTHING into one giant dataset\n",
    "trainval_df = pd.concat([df_train, df_val, df_test], ignore_index=True)\n",
    "\n",
    "# 5. Verify the size (Should be > 8,500)\n",
    "print(f\"Total Examples: {len(trainval_df)}\")\n",
    "print(trainval_df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa4d33d-5d37-4e00-b32a-d832bcd4385b",
   "metadata": {},
   "source": [
    "**Examples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f8bee10-1cf5-47e7-a19c-2cd51ebbacba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜî ID: A28426\n",
      "üì¢ CONCLUSION: Payday loans should be banned\n",
      "‚öñÔ∏è STANCE: in favor of\n",
      "üìù PREMISE: payday loans should be banned because it causes people to go into debt\n",
      "------------------------------\n",
      "üß† ACTUAL HUMAN VALUES (Ground Truth):\n",
      "   ‚úÖ Power: resources\n",
      "   ‚úÖ Security: personal\n",
      "================================================================================\n",
      "\n",
      "üÜî ID: A21315\n",
      "üì¢ CONCLUSION: Homeopathy brings more harm than good\n",
      "‚öñÔ∏è STANCE: in favor of\n",
      "üìù PREMISE: introducing items that normally produce symptoms of a disease is something that really could do more harm than good in the long run.\n",
      "------------------------------\n",
      "üß† ACTUAL HUMAN VALUES (Ground Truth):\n",
      "   ‚úÖ Security: personal\n",
      "   ‚úÖ Universalism: objectivity\n",
      "================================================================================\n",
      "\n",
      "üÜî ID: A25015\n",
      "üì¢ CONCLUSION: Payday loans should be banned\n",
      "‚öñÔ∏è STANCE: in favor of\n",
      "üìù PREMISE: payday loans allow people to spend money they do not have yet and then they have to pay interest on the loan.  this could cause them to need another loan to get through the next pay period.\n",
      "------------------------------\n",
      "üß† ACTUAL HUMAN VALUES (Ground Truth):\n",
      "   ‚úÖ Power: resources\n",
      "   ‚úÖ Security: personal\n",
      "   ‚úÖ Universalism: concern\n",
      "================================================================================\n",
      "\n",
      "üÜî ID: A28416\n",
      "üì¢ CONCLUSION: Intelligence tests bring more harm than good\n",
      "‚öñÔ∏è STANCE: in favor of\n",
      "üìù PREMISE: intelligence tests could label a child as unintelligent when they are not fully developed and so stunt their intellectual growth by placing them in lower levels\n",
      "------------------------------\n",
      "üß† ACTUAL HUMAN VALUES (Ground Truth):\n",
      "   ‚úÖ Achievement\n",
      "   ‚úÖ Face\n",
      "   ‚úÖ Universalism: concern\n",
      "================================================================================\n",
      "\n",
      "üÜî ID: A21211\n",
      "üì¢ CONCLUSION: Entrapment should be legalized\n",
      "‚öñÔ∏è STANCE: in favor of\n",
      "üìù PREMISE: entrapment should be legalized because it gets a lot of the bad guys off the streets\n",
      "------------------------------\n",
      "üß† ACTUAL HUMAN VALUES (Ground Truth):\n",
      "   ‚úÖ Security: societal\n",
      "   ‚úÖ Conformity: rules\n",
      "   ‚úÖ Universalism: concern\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Load the Data\n",
    "# Using validation set because it's cleaner for inspection\n",
    "df_args = pd.read_csv(\"data/arguments-validation.tsv\", sep='\\t')\n",
    "df_labels = pd.read_csv(\"data/labels-validation.tsv\", sep='\\t')\n",
    "\n",
    "# 2. Merge them\n",
    "val_df = pd.merge(df_args, df_labels, on=\"Argument ID\")\n",
    "\n",
    "# 3. Identify the Value Columns (The 19 or 20 labels)\n",
    "# We exclude the text columns to find just the label columns\n",
    "metadata_cols = ['Argument ID', 'Conclusion', 'Stance', 'Premise', 'Language']\n",
    "value_cols = [col for col in val_df.columns if col not in metadata_cols]\n",
    "\n",
    "# 4. Display 5 Random Examples\n",
    "# Change random_state to see different examples\n",
    "samples = val_df.sample(5, random_state=42) \n",
    "\n",
    "for idx, row in samples.iterrows():\n",
    "    print(f\"üÜî ID: {row['Argument ID']}\")\n",
    "    print(f\"üì¢ CONCLUSION: {row['Conclusion']}\")\n",
    "    print(f\"‚öñÔ∏è STANCE: {row['Stance']}\")\n",
    "    print(f\"üìù PREMISE: {row['Premise']}\")\n",
    "    print(\"-\" * 30)\n",
    "    print(\"üß† ACTUAL HUMAN VALUES (Ground Truth):\")\n",
    "    \n",
    "    # Iterate through the columns and print only the ones marked as '1'\n",
    "    has_values = False\n",
    "    for val in value_cols:\n",
    "        if row[val] == 1:\n",
    "            print(f\"   ‚úÖ {val}\")\n",
    "            has_values = True\n",
    "            \n",
    "    if not has_values:\n",
    "        print(\"   (No values annotated)\")\n",
    "        \n",
    "    print(\"=\" * 80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7455bbe9-a4a9-4d8b-a653-a7f33e4c4cfd",
   "metadata": {},
   "source": [
    "**Use iterative-stratification library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47f02b65-07d9-46a5-83e2-8fc5587882e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.13.7 environment at: /home/alumno/py313ml/.venv\u001b[0m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m6 packages\u001b[0m \u001b[2min 313ms\u001b[0m\u001b[0m                                         \u001b[0m\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 20ms\u001b[0m\u001b[0m                                               \n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 2ms\u001b[0m\u001b[0mation==0.1.9                      \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1miterative-stratification\u001b[0m\u001b[2m==0.1.9\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install iterative-stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00857a72-d4f0-4e8b-84d5-d8d64b2f7438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (8865,)\n",
      "Labels shape:   (8865, 19)\n",
      "------------------------------\n",
      "Final Training Set: 7092 examples (Use for Cross-Validation)\n",
      "Final Test Set:     1773 examples (Use for Report)\n",
      "\n",
      "Label Distribution Check (First 3 labels):\n",
      "Train: [0.15595037 0.25747321 0.05217146]\n",
      "Test:  [0.15566836 0.2571912  0.05188945]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "\n",
    "# 1. Create the Input Feature (X) and Targets (y) from your NEW trainval_df\n",
    "# Concatenate Conclusion + Stance + Premise\n",
    "trainval_df['text'] = trainval_df['Conclusion'] + \" \" + trainval_df['Stance'] + \" \" + trainval_df['Premise']\n",
    "\n",
    "label_cols = [\n",
    "    'Self-direction: thought', 'Self-direction: action', 'Stimulation',\n",
    "    'Hedonism', 'Achievement', 'Power: dominance', 'Power: resources',\n",
    "    'Face', 'Security: personal', 'Security: societal', 'Tradition',\n",
    "    'Conformity: rules', 'Conformity: interpersonal', 'Humility',\n",
    "    'Benevolence: caring', 'Benevolence: dependability',\n",
    "    'Universalism: concern', 'Universalism: nature', 'Universalism: tolerance'\n",
    "]\n",
    "\n",
    "# Create the arrays for splitting\n",
    "X_all = trainval_df['text'].values\n",
    "y_all = trainval_df[label_cols].values\n",
    "\n",
    "print(f\"Features shape: {X_all.shape}\")\n",
    "print(f\"Labels shape:   {y_all.shape}\")\n",
    "\n",
    "# 2. Iterative Stratified Split (Train vs Test)\n",
    "# We use X_all and y_all here\n",
    "msss = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "# FIX: Use 'X_all' and 'y_all' inside the loop\n",
    "for train_index, test_index in msss.split(X_all, y_all):\n",
    "    X_train, X_test = X_all[train_index], X_all[test_index]\n",
    "    y_train, y_test = y_all[train_index], y_all[test_index]\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"Final Training Set: {X_train.shape[0]} examples (Use for Cross-Validation)\")\n",
    "print(f\"Final Test Set:     {X_test.shape[0]} examples (Use for Report)\")\n",
    "\n",
    "# OPTIONAL: Sanity Check\n",
    "print(\"\\nLabel Distribution Check (First 3 labels):\")\n",
    "print(f\"Train: {np.mean(y_train, axis=0)[:3]}\")\n",
    "print(f\"Test:  {np.mean(y_test, axis=0)[:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab54c150-3abe-4b02-b799-51af266d77ff",
   "metadata": {},
   "source": [
    "**SPARSE REPRESENTATION**\n",
    "\n",
    "We compare TF-IDF approach with CountVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9dba088e-27ce-4aa0-a759-f1da610fd378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Type | N-Grams    | Mean F1-Macro   | Std Dev   \n",
      "------------------------------------------------------------\n",
      "TF-IDF       | (1, 1)     | 0.2656          | 0.0060\n",
      "TF-IDF       | (1, 2)     | 0.2707          | 0.0082\n",
      "TF-IDF       | (1, 3)     | 0.2866          | 0.0073\n",
      "CountVec     | (1, 1)     | 0.4005          | 0.0082\n",
      "CountVec     | (1, 2)     | 0.4286          | 0.0075\n",
      "CountVec     | (1, 3)     | 0.4322          | 0.0072\n",
      "------------------------------------------------------------\n",
      "üèÜ WINNER: CountVec (1, 3) with F1-Macro: 0.4322\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "import numpy as np\n",
    "\n",
    "# 1. Setup the Cross-Validation Strategy (Mandatory)\n",
    "# Matches your data splitting logic (Stratified Multi-label)\n",
    "stratified_cv = MultilabelStratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 2. Define Experiments\n",
    "# We test different Feature Types AND N-gram ranges\n",
    "experiments = [\n",
    "    (\"TF-IDF\", (1, 1)),      # Standard baseline\n",
    "    (\"TF-IDF\", (1, 2)),      # Captures phrases (\"climate change\")\n",
    "    (\"TF-IDF\", (1, 3)),      # Captures longer context\n",
    "    (\"CountVec\", (1, 1)),    # Raw frequency (Bag of Words)\n",
    "    (\"CountVec\", (1, 2)),    # Raw frequency + Phrases\n",
    "    (\"CountVec\", (1, 3)),    # Trigrams\n",
    "]\n",
    "\n",
    "print(f\"{'Feature Type':<12} | {'N-Grams':<10} | {'Mean F1-Macro':<15} | {'Std Dev':<10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "best_score = 0\n",
    "best_config = \"\"\n",
    "\n",
    "for vec_type, ngram in experiments:\n",
    "    # 3. Select Vectorizer\n",
    "    if vec_type == \"TF-IDF\":\n",
    "        vectorizer = TfidfVectorizer(ngram_range=ngram, min_df=3, max_features=20000)\n",
    "    else:\n",
    "        vectorizer = CountVectorizer(ngram_range=ngram, min_df=3, max_features=20000)\n",
    "        \n",
    "    # 4. Build Pipeline\n",
    "    # Using Logistic Regression (OneVsRest) as the standard baseline classifier\n",
    "    pipeline = Pipeline([\n",
    "        ('vec', vectorizer),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression(solver='liblinear', random_state=42)))\n",
    "    ])\n",
    "    \n",
    "    # 5. Run Cross-Validation\n",
    "    scores = cross_val_score(pipeline, X_train, y_train, cv=stratified_cv, scoring='f1_macro', n_jobs=-1)\n",
    "    \n",
    "    # 6. Store Results\n",
    "    mean_score = scores.mean()\n",
    "    std_score = scores.std()\n",
    "    \n",
    "    print(f\"{vec_type:<12} | {str(ngram):<10} | {mean_score:.4f}          | {std_score:.4f}\")\n",
    "    \n",
    "    if mean_score > best_score:\n",
    "        best_score = mean_score\n",
    "        best_config = f\"{vec_type} {ngram}\"\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(f\"üèÜ WINNER: {best_config} with F1-Macro: {best_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ca8c7e-ffab-4b92-aa3d-744691ea6fcb",
   "metadata": {},
   "source": [
    "*Feature representation analysis:*\n",
    "\n",
    "- Our experiments revealed that CountVectors (Raw Frequency) significantly outperformed TF-IDF. This suggests that for short argumentation texts, the raw presence of specific value-laden keywords (e.g., 'freedom', 'security') is the most predictive feature.\n",
    "\n",
    "- TF-IDF attempts to down-weight common terms, but in this domain, high-frequency terms are often the exact class identifiers we need. Since BM25 is mathematically an extension of TF-IDF (designed to further penalize term saturation and normalize length), it inherits the same 'flaw' for this specific dataset.\n",
    "\n",
    "- Consequently, because the simpler CountVectors model already outperforms the weighted TF-IDF model by a large margin, we conclude that complex frequency dampening (like that in BM25) is unnecessary and detrimental for this specific task. We therefore selected CountVectors (N-gram 1,2) as our optimal Sparse baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b70dc9-e697-494f-8569-a9054cc64d14",
   "metadata": {},
   "source": [
    "**Dense Methods**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8154dc2-a4a8-4879-81dc-ca72e0645573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name           | Dimensions | Mean F1-Macro   | Std Dev   \n",
      "-----------------------------------------------------------------\n",
      "GloVe (100d)         | 100        | 0.2791          | 0.0051\n",
      "Word2Vec (300d)      | 300        | nan          | nan\n",
      "-----------------------------------------------------------------\n",
      "üèÜ Best Dense Model: GloVe (100d) with F1: 0.2791\n",
      "Sparse Baseline:     0.4322\n",
      "üìâ Result: Sparse Features (CountVec/TF-IDF) are SUPERIOR.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alumno/py313ml/.venv/lib/python3.13/site-packages/sklearn/model_selection/_validation.py:516: FitFailedWarning: \n",
      "2 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/alumno/py313ml/.venv/lib/python3.13/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/alumno/py313ml/.venv/lib/python3.13/site-packages/sklearn/base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/home/alumno/py313ml/.venv/lib/python3.13/site-packages/sklearn/pipeline.py\", line 655, in fit\n",
      "    Xt = self._fit(X, y, routed_params, raw_params=params)\n",
      "  File \"/home/alumno/py313ml/.venv/lib/python3.13/site-packages/sklearn/pipeline.py\", line 589, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        cloned_transformer,\n",
      "        ^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "        params=step_params,\n",
      "        ^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/home/alumno/py313ml/.venv/lib/python3.13/site-packages/joblib/memory.py\", line 326, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/alumno/py313ml/.venv/lib/python3.13/site-packages/sklearn/pipeline.py\", line 1540, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "  File \"/home/alumno/py313ml/.venv/lib/python3.13/site-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"/home/alumno/py313ml/.venv/lib/python3.13/site-packages/sklearn/base.py\", line 897, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_230242/1489744421.py\", line 19, in fit\n",
      "  File \"/home/alumno/py313ml/.venv/lib/python3.13/site-packages/gensim/downloader.py\", line 490, in load\n",
      "    file_name = _get_filename(name)\n",
      "  File \"/home/alumno/py313ml/.venv/lib/python3.13/site-packages/gensim/downloader.py\", line 426, in _get_filename\n",
      "    information = info()\n",
      "  File \"/home/alumno/py313ml/.venv/lib/python3.13/site-packages/gensim/downloader.py\", line 268, in info\n",
      "    information = _load_info()\n",
      "  File \"/home/alumno/py313ml/.venv/lib/python3.13/site-packages/gensim/downloader.py\", line 220, in _load_info\n",
      "    return json.load(fin)\n",
      "           ~~~~~~~~~^^^^^\n",
      "  File \"/home/alumno/.local/share/uv/python/cpython-3.13.7-linux-x86_64-gnu/lib/python3.13/json/__init__.py\", line 293, in load\n",
      "    return loads(fp.read(),\n",
      "        cls=cls, object_hook=object_hook,\n",
      "        parse_float=parse_float, parse_int=parse_int,\n",
      "        parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n",
      "  File \"/home/alumno/.local/share/uv/python/cpython-3.13.7-linux-x86_64-gnu/lib/python3.13/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~^^^\n",
      "  File \"/home/alumno/.local/share/uv/python/cpython-3.13.7-linux-x86_64-gnu/lib/python3.13/json/decoder.py\", line 345, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "               ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/alumno/.local/share/uv/python/cpython-3.13.7-linux-x86_64-gnu/lib/python3.13/json/decoder.py\", line 363, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading glove-wiki-gigaword-100...\n",
      "Loading word2vec-google-news-300...\n",
      "Loading glove-wiki-gigaword-100...\n",
      "Loading glove-wiki-gigaword-100...\n",
      "Loading word2vec-google-news-300...\n",
      "Loading glove-wiki-gigaword-100...\n",
      "Loading word2vec-google-news-300...\n",
      "Loading word2vec-google-news-300...\n",
      "Loading glove-wiki-gigaword-100...\n",
      "Loading word2vec-google-news-300...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gensim.downloader as api\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# 1. Define the Vectorizer (Averaging Logic)\n",
    "class MeanEmbeddingVectorizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, model_name):\n",
    "        self.model_name = model_name\n",
    "        self.word2vec = None\n",
    "        self.dim = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Load the model only when fitting to save memory/time if not used\n",
    "        print(f\"Loading {self.model_name}...\")\n",
    "        self.word2vec = api.load(self.model_name)\n",
    "        self.dim = self.word2vec.vector_size\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Check if model is loaded\n",
    "        if self.word2vec is None:\n",
    "             self.word2vec = api.load(self.model_name)\n",
    "             self.dim = self.word2vec.vector_size\n",
    "             \n",
    "        return np.array([\n",
    "            np.mean([self.word2vec[w] for w in words if w in self.word2vec]\n",
    "                    or [np.zeros(self.dim)], axis=0)\n",
    "            for words in [s.lower().split() for s in X]\n",
    "        ])\n",
    "\n",
    "# 2. Define the Models to Compare\n",
    "# Format: (Display Name, Gensim API Name)\n",
    "dense_models = [\n",
    "    (\"GloVe (100d)\", \"glove-wiki-gigaword-100\"),\n",
    "    (\"Word2Vec (300d)\", \"word2vec-google-news-300\") \n",
    "]\n",
    "\n",
    "print(f\"{'Model Name':<20} | {'Dimensions':<10} | {'Mean F1-Macro':<15} | {'Std Dev':<10}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "results_dense = {}\n",
    "\n",
    "for display_name, api_name in dense_models:\n",
    "    # 3. Build Pipeline\n",
    "    # We initialize the vectorizer with the model name, it loads during fit()\n",
    "    pipeline = Pipeline([\n",
    "        ('vec', MeanEmbeddingVectorizer(api_name)),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression(solver='liblinear', random_state=42)))\n",
    "    ])\n",
    "    \n",
    "    # 4. Run Cross-Validation\n",
    "    # Note: This might be slower due to the large matrix operations in 300d\n",
    "    scores = cross_val_score(pipeline, X_train, y_train, cv=stratified_cv, scoring='f1_macro', n_jobs=-1)\n",
    "    \n",
    "    # 5. Store and Print\n",
    "    mean_score = scores.mean()\n",
    "    results_dense[display_name] = mean_score\n",
    "    print(f\"{display_name:<20} | {str(300 if '300' in api_name else 100):<10} | {mean_score:.4f}          | {scores.std():.4f}\")\n",
    "\n",
    "# 6. Final Comparison\n",
    "best_dense = max(results_dense, key=results_dense.get)\n",
    "print(\"-\" * 65)\n",
    "print(f\"üèÜ Best Dense Model: {best_dense} with F1: {results_dense[best_dense]:.4f}\")\n",
    "\n",
    "# Optional: Compare against your Sparse Baseline (assuming 'best_score' exists)\n",
    "try:\n",
    "    print(f\"Sparse Baseline:     {best_score:.4f}\")\n",
    "    if results_dense[best_dense] > best_score:\n",
    "        print(\"üöÄ Result: Dense Embeddings BEAT Sparse Features!\")\n",
    "    else:\n",
    "        print(\"üìâ Result: Sparse Features (CountVec/TF-IDF) are SUPERIOR.\")\n",
    "except NameError:\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
