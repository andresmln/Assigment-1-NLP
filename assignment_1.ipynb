{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e1ff66b-76d5-4d66-988e-31213289f62e",
   "metadata": {},
   "source": [
    "**First we load and merge train, val and test datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95206848-e7d9-4cd7-a856-0817772dbfff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Examples: 8865\n",
      "  Argument ID                                   Conclusion       Stance  \\\n",
      "0      A01002                  We should ban human cloning  in favor of   \n",
      "1      A01005                      We should ban fast food  in favor of   \n",
      "2      A01006  We should end the use of economic sanctions      against   \n",
      "\n",
      "                                             Premise  Self-direction: thought  \\\n",
      "0  we should ban human cloning as it will only ca...                        0   \n",
      "1  fast food should be banned because it is reall...                        0   \n",
      "2  sometimes economic sanctions are the only thin...                        0   \n",
      "\n",
      "   Self-direction: action  Stimulation  Hedonism  Achievement  \\\n",
      "0                       0            0         0            0   \n",
      "1                       0            0         0            0   \n",
      "2                       0            0         0            0   \n",
      "\n",
      "   Power: dominance  ...  Tradition  Conformity: rules  \\\n",
      "0                 0  ...          0                  0   \n",
      "1                 0  ...          0                  0   \n",
      "2                 1  ...          0                  0   \n",
      "\n",
      "   Conformity: interpersonal  Humility  Benevolence: caring  \\\n",
      "0                          0         0                    0   \n",
      "1                          0         0                    0   \n",
      "2                          0         0                    0   \n",
      "\n",
      "   Benevolence: dependability  Universalism: concern  Universalism: nature  \\\n",
      "0                           0                      0                     0   \n",
      "1                           0                      0                     0   \n",
      "2                           0                      0                     0   \n",
      "\n",
      "   Universalism: tolerance  Universalism: objectivity  \n",
      "0                        0                          0  \n",
      "1                        0                          0  \n",
      "2                        0                          0  \n",
      "\n",
      "[3 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Load Training Data\n",
    "train_args = pd.read_csv(\"data/arguments-training.tsv\", sep='\\t')\n",
    "train_labels = pd.read_csv(\"data/labels-training.tsv\", sep='\\t')\n",
    "df_train = pd.merge(train_args, train_labels, on=\"Argument ID\")\n",
    "\n",
    "# 2. Load Validation Data\n",
    "val_args = pd.read_csv(\"data/arguments-validation.tsv\", sep='\\t')\n",
    "val_labels = pd.read_csv(\"data/labels-validation.tsv\", sep='\\t')\n",
    "df_val = pd.merge(val_args, val_labels, on=\"Argument ID\")\n",
    "\n",
    "# 3. Load Test Data (Crucial for volume!)\n",
    "test_args = pd.read_csv(\"data/arguments-test.tsv\", sep='\\t')\n",
    "test_labels = pd.read_csv(\"data/labels-test.tsv\", sep='\\t')\n",
    "df_test = pd.merge(test_args, test_labels, on=\"Argument ID\")\n",
    "\n",
    "# 4. Concatenate EVERYTHING into one giant dataset\n",
    "trainval_df = pd.concat([df_train, df_val, df_test], ignore_index=True)\n",
    "\n",
    "# 5. Verify the size (Should be > 8,500)\n",
    "print(f\"Total Examples: {len(trainval_df)}\")\n",
    "print(trainval_df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa4d33d-5d37-4e00-b32a-d832bcd4385b",
   "metadata": {},
   "source": [
    "**Examples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f8bee10-1cf5-47e7-a19c-2cd51ebbacba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜî ID: A28426\n",
      "üì¢ CONCLUSION: Payday loans should be banned\n",
      "‚öñÔ∏è STANCE: in favor of\n",
      "üìù PREMISE: payday loans should be banned because it causes people to go into debt\n",
      "------------------------------\n",
      "üß† ACTUAL HUMAN VALUES (Ground Truth):\n",
      "   ‚úÖ Power: resources\n",
      "   ‚úÖ Security: personal\n",
      "================================================================================\n",
      "\n",
      "üÜî ID: A21315\n",
      "üì¢ CONCLUSION: Homeopathy brings more harm than good\n",
      "‚öñÔ∏è STANCE: in favor of\n",
      "üìù PREMISE: introducing items that normally produce symptoms of a disease is something that really could do more harm than good in the long run.\n",
      "------------------------------\n",
      "üß† ACTUAL HUMAN VALUES (Ground Truth):\n",
      "   ‚úÖ Security: personal\n",
      "   ‚úÖ Universalism: objectivity\n",
      "================================================================================\n",
      "\n",
      "üÜî ID: A25015\n",
      "üì¢ CONCLUSION: Payday loans should be banned\n",
      "‚öñÔ∏è STANCE: in favor of\n",
      "üìù PREMISE: payday loans allow people to spend money they do not have yet and then they have to pay interest on the loan.  this could cause them to need another loan to get through the next pay period.\n",
      "------------------------------\n",
      "üß† ACTUAL HUMAN VALUES (Ground Truth):\n",
      "   ‚úÖ Power: resources\n",
      "   ‚úÖ Security: personal\n",
      "   ‚úÖ Universalism: concern\n",
      "================================================================================\n",
      "\n",
      "üÜî ID: A28416\n",
      "üì¢ CONCLUSION: Intelligence tests bring more harm than good\n",
      "‚öñÔ∏è STANCE: in favor of\n",
      "üìù PREMISE: intelligence tests could label a child as unintelligent when they are not fully developed and so stunt their intellectual growth by placing them in lower levels\n",
      "------------------------------\n",
      "üß† ACTUAL HUMAN VALUES (Ground Truth):\n",
      "   ‚úÖ Achievement\n",
      "   ‚úÖ Face\n",
      "   ‚úÖ Universalism: concern\n",
      "================================================================================\n",
      "\n",
      "üÜî ID: A21211\n",
      "üì¢ CONCLUSION: Entrapment should be legalized\n",
      "‚öñÔ∏è STANCE: in favor of\n",
      "üìù PREMISE: entrapment should be legalized because it gets a lot of the bad guys off the streets\n",
      "------------------------------\n",
      "üß† ACTUAL HUMAN VALUES (Ground Truth):\n",
      "   ‚úÖ Security: societal\n",
      "   ‚úÖ Conformity: rules\n",
      "   ‚úÖ Universalism: concern\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Load the Data\n",
    "# Using validation set because it's cleaner for inspection\n",
    "df_args = pd.read_csv(\"data/arguments-validation.tsv\", sep='\\t')\n",
    "df_labels = pd.read_csv(\"data/labels-validation.tsv\", sep='\\t')\n",
    "\n",
    "# 2. Merge them\n",
    "val_df = pd.merge(df_args, df_labels, on=\"Argument ID\")\n",
    "\n",
    "# 3. Identify the Value Columns (The 19 or 20 labels)\n",
    "# We exclude the text columns to find just the label columns\n",
    "metadata_cols = ['Argument ID', 'Conclusion', 'Stance', 'Premise', 'Language']\n",
    "value_cols = [col for col in val_df.columns if col not in metadata_cols]\n",
    "\n",
    "# 4. Display 5 Random Examples\n",
    "# Change random_state to see different examples\n",
    "samples = val_df.sample(5, random_state=42) \n",
    "\n",
    "for idx, row in samples.iterrows():\n",
    "    print(f\"üÜî ID: {row['Argument ID']}\")\n",
    "    print(f\"üì¢ CONCLUSION: {row['Conclusion']}\")\n",
    "    print(f\"‚öñÔ∏è STANCE: {row['Stance']}\")\n",
    "    print(f\"üìù PREMISE: {row['Premise']}\")\n",
    "    print(\"-\" * 30)\n",
    "    print(\"üß† ACTUAL HUMAN VALUES (Ground Truth):\")\n",
    "    \n",
    "    # Iterate through the columns and print only the ones marked as '1'\n",
    "    has_values = False\n",
    "    for val in value_cols:\n",
    "        if row[val] == 1:\n",
    "            print(f\"   ‚úÖ {val}\")\n",
    "            has_values = True\n",
    "            \n",
    "    if not has_values:\n",
    "        print(\"   (No values annotated)\")\n",
    "        \n",
    "    print(\"=\" * 80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7455bbe9-a4a9-4d8b-a653-a7f33e4c4cfd",
   "metadata": {},
   "source": [
    "**Use iterative-stratification library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47f02b65-07d9-46a5-83e2-8fc5587882e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.13.7 environment at: /home/alumno/py313ml/.venv\u001b[0m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m6 packages\u001b[0m \u001b[2min 313ms\u001b[0m\u001b[0m                                         \u001b[0m\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 20ms\u001b[0m\u001b[0m                                               \n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 2ms\u001b[0m\u001b[0mation==0.1.9                      \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1miterative-stratification\u001b[0m\u001b[2m==0.1.9\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install iterative-stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00857a72-d4f0-4e8b-84d5-d8d64b2f7438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (8865,)\n",
      "Labels shape:   (8865, 19)\n",
      "------------------------------\n",
      "Final Training Set: 7092 examples (Use for Cross-Validation)\n",
      "Final Test Set:     1773 examples (Use for Report)\n",
      "\n",
      "Label Distribution Check (First 3 labels):\n",
      "Train: [0.15595037 0.25747321 0.05217146]\n",
      "Test:  [0.15566836 0.2571912  0.05188945]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "\n",
    "# 1. Create the Input Feature (X) and Targets (y) from your NEW trainval_df\n",
    "# Concatenate Conclusion + Stance + Premise\n",
    "trainval_df['text'] = trainval_df['Conclusion'] + \" \" + trainval_df['Stance'] + \" \" + trainval_df['Premise']\n",
    "\n",
    "label_cols = [\n",
    "    'Self-direction: thought', 'Self-direction: action', 'Stimulation',\n",
    "    'Hedonism', 'Achievement', 'Power: dominance', 'Power: resources',\n",
    "    'Face', 'Security: personal', 'Security: societal', 'Tradition',\n",
    "    'Conformity: rules', 'Conformity: interpersonal', 'Humility',\n",
    "    'Benevolence: caring', 'Benevolence: dependability',\n",
    "    'Universalism: concern', 'Universalism: nature', 'Universalism: tolerance'\n",
    "]\n",
    "\n",
    "# Create the arrays for splitting\n",
    "X_all = trainval_df['text'].values\n",
    "y_all = trainval_df[label_cols].values\n",
    "\n",
    "print(f\"Features shape: {X_all.shape}\")\n",
    "print(f\"Labels shape:   {y_all.shape}\")\n",
    "\n",
    "# 2. Iterative Stratified Split (Train vs Test)\n",
    "# We use X_all and y_all here\n",
    "msss = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "# FIX: Use 'X_all' and 'y_all' inside the loop\n",
    "for train_index, test_index in msss.split(X_all, y_all):\n",
    "    X_train, X_test = X_all[train_index], X_all[test_index]\n",
    "    y_train, y_test = y_all[train_index], y_all[test_index]\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"Final Training Set: {X_train.shape[0]} examples (Use for Cross-Validation)\")\n",
    "print(f\"Final Test Set:     {X_test.shape[0]} examples (Use for Report)\")\n",
    "\n",
    "# OPTIONAL: Sanity Check\n",
    "print(\"\\nLabel Distribution Check (First 3 labels):\")\n",
    "print(f\"Train: {np.mean(y_train, axis=0)[:3]}\")\n",
    "print(f\"Test:  {np.mean(y_test, axis=0)[:3]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
